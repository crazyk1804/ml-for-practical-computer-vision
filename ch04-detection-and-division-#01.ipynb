{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <b style=\"color: #abcdef\">04.객체 검출과 이미지 세분화 - 객체검출(Detection)</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> #### <b style=\"color: #58a491\">f86461</b>\n",
    "> - 컨볼루션 레이어는 위치정보를 추출함\n",
    "> - 컨볼루션 스택에 요소추가하여 네트워크 훈련"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> #### <b style=\"color: #f86461\">YOLO</b>\n",
    "> - 컨볼루션 백본 끝에 요소 추가  \n",
    "> ---\n",
    "> <b style=\"color: #53a593\">YOLO 격자</b>\n",
    "> - 이미지 분할 N * M \n",
    "> - 중심좌표, 너비, 높이, 확신도 => (x, y, w, h, C)  \n",
    "> - 객체 검출 헤드 5(x, y, w, h, C)  + class수 채널  \n",
    "> ---\n",
    "> <b style=\"color: #53a593\">손실</b>\n",
    "> - 객체존재손실: (1-C)**2\n",
    "> - 객체부재손실: (0-C)\\**2 = C**2\n",
    "> - 객체분류손실: cross_entropy\n",
    "> - 경계박스손실: (x-x^)**2 + (y-y^)**2 + (sqrt(w) - sqrt(w^)) ** 2 + (sqrt(h) - sqrt(h^))**2  \n",
    "> ---\n",
    "> <b style=\"color: #53a593\">손실가중치</b> - 객체 부재의 손실이 압도적으로 많아 객체 존재 손실이 묻힌다\n",
    "> - 객체존재손실: 1\n",
    "> - 객체부재손실: 0.5\n",
    "> - 객체분류손실: 1\n",
    "> - 경계박스손실: 5  \n",
    "> <b style=\"color: #53a593\">한계</b> - 격자셀당 하나의 객체만 인식 가능  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> #### <b style=\"color: #f86461\">레티나넷(RetinaNet)</b>\n",
    "> ---\n",
    "> <b style=\"color: #53a593\">FPN</b>\n",
    "> - 저수준의 공간정보 + CNN의 고수준 의미정보 (상위 특징맵 + 하위 특징맵 업샘플링 + 검출헤드)  \n",
    "> ---\n",
    ">   <b style=\"color: #53a593\">앵커박스</b>\n",
    "> - 종횡비: 2:1, 1:1, 1:2\n",
    "> - 크기: 2\\*\\*0, 2\\*\\*(1/3), 2**(2/3) (대략 1, 1.3, 1.6)\n",
    "> - 스케일: P3 ~ P7 (2**n => 8, 16, 32, 64, 128, 256, 512)\n",
    "> - 앵커베이스 크기 4*2**n => 32, 64, 128, 256, 512 <b style=\"color: #ff5555\">뭔소린지 전혀 모르겠다</b>\n",
    "> - 앵커박스 간격 8, 16, 32, 64, 128, 256, 512\n",
    "> - 앵커박스 크기: (32, 32) ~ (812, 1624) <== (512 * 2**(2/3), 512 * 2**(2/3) * 2)  \n",
    "> ---\n",
    "> <b style=\"color: #53a593\">검출손실</b>  \n",
    "> - ![anchor-iou-matrix](./resources/anchor-iou-matrix.png)  \n",
    "> ---\n",
    "> <b style=\"color: #53a593\">아키텍처</b>  \n",
    "> - K = 클래스 수, B = 박스형태 수(3가지 비율, 3가지 크기 = 9)  \n",
    "> - 클래스 예측헤드: 클래스 수만큼 모든 앵커에 대한 확률 예측 (K * 9)  \n",
    "> - 검출헤드: B * 4개 박스델타 예측 (x, y, w, h) => 9 * 4 = 36  \n",
    "> ---\n",
    "> <b style=\"color: #53a593\">초점손실(focal loss)</b>  \n",
    "> - **뭐라는거야...**  \n",
    "> - 배경 앵커가 갖는 손실값 **총합**이 너무 커서(많으니까) 기여도를 많이 줄여서 그 영향을 줄이는 개념  \n",
    "> - CE(y, p) = -y*log(p) - (1-y)*log(1-p)\n",
    "> - FL(y, p) = -y\\*log(p)*(1-p)**γ - (1-y)*log(1-p)*p\\**γ  \n",
    "> ---\n",
    "> <b style=\"color: #53a593\">부드러운 L1손실</b>  \n",
    "> - L1 = 절대손실, L2 = 제곱 손실(squared) -- mean squared error? --\n",
    "> - L1은 미분이 안되고 L2는 손실이 크면 지나치게 커짐 -> δ 지정하여 구간별로 앞부분 L2, 뒷부분 L1\n",
    "> - ![anchor-iou-matrix](./resources/smooth-l1.png)\n",
    "> - ![anchor-iou-matrix](./resources/smooth-l1-v2.png)\n",
    "> ---\n",
    "> <b style=\"color: #53a593\">NMS(Non Maximum Supression)</b>  \n",
    "> - IOU가 임계값 이상인 박스 그룹에서 확신도가 최대인 박스만 남긴다  \n",
    "> - 근접한 객체가 삭제될 소지가 있다(IOU가 생기니까)\n",
    "> - Soft-NMS 를 사용해서 박스를 없애지 않고 C값을 낮춰 해결 -> 검출목록은 σ값이 결정(뭔지는 잘..)\n",
    "> ---\n",
    "> <b style=\"color: #53a593\">그밖의 고려사항...</b>  \n",
    "> - <b style=\"color: #f09433\">레티나넷 얘기하다가 뭔 고려사항이여</b>\n",
    "> - 데이터 증강 하란다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <b style=\"color: #abcdef\">04.객체 검출과 이미지 세분화 - 세분화(Segmentation)</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
