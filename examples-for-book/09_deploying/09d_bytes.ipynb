{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 109
        },
        "id": "hiQ6zAoYhyaA",
        "outputId": "13fd8f2d-94bb-433d-e269-ca4397195c28"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "<table class=\"tfo-notebook-buttons\" align=\"left\"><td><a target=\"_blank\" href=\"https://console.cloud.google.com/ai-platform/notebooks/deploy-notebook?name=%EC%9D%B4%EB%AF%B8%EC%A7%80+%EB%B0%94%EC%9D%B4%ED%8A%B8+%EB%8B%A4%EB%A3%A8%EA%B8%B0&download_url=https%3A%2F%2Fgithub.com%2Fychoi-kr%2Fpractical-ml-vision-book-ko%2Fraw%2Fmaster%2F09_deploying%2F09d_bytes.ipynb\"><img src=\"https://raw.githubusercontent.com/ychoi-kr/practical-ml-vision-book-ko/master/logo-cloud.png\"/>AI Platform Notebook에서 실행</a></td><td><a target=\"_blank\" href=\"https://colab.research.google.com/github/ychoi-kr/practical-ml-vision-book-ko/blob/master/09_deploying/09d_bytes.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Google Colab에서 실행</a></td><td><a target=\"_blank\" href=\"https://github.com/ychoi-kr/practical-ml-vision-book-ko/blob/master/09_deploying/09d_bytes.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />GitHub에서 소스 보기</a></td><td><a href=\"https://raw.githubusercontent.com/ychoi-kr/practical-ml-vision-book-ko/master/09_deploying/09d_bytes.ipynb\"><img src=\"https://www.tensorflow.org/images/download_logo_32px.png\" />노트북 내려받기</a></td></table><br/><br/><h1>이미지 바이트 다루기</h1>"
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "import urllib\n",
        "from IPython.display import Markdown as md\n",
        "\n",
        "### change to reflect your notebook\n",
        "_nb_loc = \"09_deploying/09d_bytes.ipynb\"\n",
        "_nb_title = \"이미지 바이트 다루기\"\n",
        "_nb_message = \"\"\n",
        "\n",
        "### no need to change any of this\n",
        "_icons=[\"https://raw.githubusercontent.com/ychoi-kr/practical-ml-vision-book-ko/master/logo-cloud.png\", \"https://www.tensorflow.org/images/colab_logo_32px.png\", \"https://www.tensorflow.org/images/GitHub-Mark-32px.png\", \"https://www.tensorflow.org/images/download_logo_32px.png\"]\n",
        "_links=[\"https://console.cloud.google.com/ai-platform/notebooks/deploy-notebook?\" + urllib.parse.urlencode({\"name\": _nb_title, \"download_url\": \"https://github.com/ychoi-kr/practical-ml-vision-book-ko/raw/master/\"+_nb_loc}), \"https://colab.research.google.com/github/ychoi-kr/practical-ml-vision-book-ko/blob/master/{0}\".format(_nb_loc), \"https://github.com/ychoi-kr/practical-ml-vision-book-ko/blob/master/{0}\".format(_nb_loc), \"https://raw.githubusercontent.com/ychoi-kr/practical-ml-vision-book-ko/master/{0}\".format(_nb_loc)]\n",
        "md(\"\"\"<table class=\"tfo-notebook-buttons\" align=\"left\"><td><a target=\"_blank\" href=\"{0}\"><img src=\"{4}\"/>AI Platform Notebook에서 실행</a></td><td><a target=\"_blank\" href=\"{1}\"><img src=\"{5}\" />Google Colab에서 실행</a></td><td><a target=\"_blank\" href=\"{2}\"><img src=\"{6}\" />GitHub에서 소스 보기</a></td><td><a href=\"{3}\"><img src=\"{7}\" />노트북 내려받기</a></td></table><br/><br/><h1>{8}</h1>{9}\"\"\".format(_links[0], _links[1], _links[2], _links[3], _icons[0], _icons[1], _icons[2], _icons[3], _nb_title, _nb_message))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a8HQYsAtC0Fv"
      },
      "source": [
        "# 이미지 바이트 다루기\n",
        "\n",
        "이 노트북에서는 앞서 훈련 및 저장한 모델(7장)을 가지고 시작한다.\n",
        "편의상 이 모델을 공개 버킷 [gs://practical-ml-vision-book/flowers_5_trained](gs://practical-ml-vision-book/flowers_5_trained)에 두었다.\n",
        "\n",
        "우리가 원하는 것은 네트워크를 통해 바이트를 직접 처리하는 것이다. 이렇게 하면 클라이언트가 Google Cloud Storage에 이미지를 저장할 필요가 없다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5UOm2etrwYCs"
      },
      "source": [
        "## GPU 활성화 및 도우미 함수 셋업\n",
        "\n",
        "이 저장소의 노트북들은 GPU를 사용하면 더 빨리 실행된다.\n",
        "\n",
        "코랩에서:\n",
        "\n",
        "- 수정 → 노트 설정 메뉴로 이동\n",
        "- 하드웨어 가속기 드롭다운에서 GPU를 선택\n",
        "\n",
        "Cloud AI Platform Notebooks에서:\n",
        "\n",
        "- [https://console.cloud.google.com/ai-platform/notebooks](https://console.cloud.google.com/ai-platform/notebooks)로 이동\n",
        "- GPU를 포함한 인스턴스를 생성하거나, 인스턴스를 선택하고 GPU를 추가\n",
        "\n",
        "다음으로, 텐서플로로 GPU에 연결할 수 있는지 확인."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ugGJcxKAwhc2"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "print('TensorFlow version' + tf.version.VERSION)\n",
        "print('Built with GPU support? ' + ('Yes!' if tf.test.is_built_with_cuda() else 'Noooo!'))\n",
        "print('There are {} GPUs'.format(len(tf.config.experimental.list_physical_devices(\"GPU\"))))\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "    raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KQoGQZ9mttDU"
      },
      "source": [
        "## 체크포인트에서 읽기\n",
        "\n",
        "시그니처만이 아닌 전체 모델을 원하므로, 저장된 모델이 아닌 *체크포인트*에서 시작한다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hYuKgYJmttDV",
        "outputId": "873611c0-5cf8-4313-9452-8c93330ddf1d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"flower_classification\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "random/center_crop (RandomCr (None, 224, 224, 3)       0         \n",
            "_________________________________________________________________\n",
            "random_lr_flip/none (RandomF (None, 224, 224, 3)       0         \n",
            "_________________________________________________________________\n",
            "mobilenet_embedding (KerasLa (None, 1280)              2257984   \n",
            "_________________________________________________________________\n",
            "dense_hidden (Dense)         (None, 32)                40992     \n",
            "_________________________________________________________________\n",
            "flower_prob (Dense)          (None, 5)                 165       \n",
            "=================================================================\n",
            "Total params: 2,299,141\n",
            "Trainable params: 2,265,029\n",
            "Non-trainable params: 34,112\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import shutil\n",
        "import tensorflow as tf\n",
        "\n",
        "CHECK_POINT_DIR='gs://practical-ml-vision-book/flowers_5_trained/chkpts'\n",
        "model = tf.keras.models.load_model(CHECK_POINT_DIR)\n",
        "print(model.summary())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m2tLupHJttDV"
      },
      "outputs": [],
      "source": [
        "IMG_HEIGHT = 345\n",
        "IMG_WIDTH = 345\n",
        "IMG_CHANNELS = 3\n",
        "CLASS_NAMES = 'daisy dandelion roses sunflowers tulips'.split()\n",
        "\n",
        "def read_from_jpegfile(filename):\n",
        "    img_bytes = tf.io.read_file(filename)\n",
        "    return img_bytes\n",
        "    \n",
        "def preprocess(img_bytes):\n",
        "    img = tf.image.decode_jpeg(img_bytes, channels=IMG_CHANNELS)\n",
        "    img = tf.image.convert_image_dtype(img, tf.float32)\n",
        "    return tf.image.resize_with_pad(img, IMG_HEIGHT, IMG_WIDTH)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zhZjEKGHttDV",
        "outputId": "89596e87-b597-406c-c275-bb1842271f0f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[0.3507376  0.3983379  0.02309519 0.07595135 0.15187794]]\n",
            "[[3.1782882e-05 9.9996090e-01 5.1874702e-07 3.2268999e-06 3.5444552e-06]]\n",
            "[[9.9471879e-01 3.5855272e-03 2.1374140e-05 1.5876008e-03 8.6639280e-05]]\n",
            "[[1.5454909e-03 2.2907292e-04 3.6099207e-02 3.1195192e-03 9.5900667e-01]]\n",
            "[[4.7941930e-06 3.9310632e-07 5.8220904e-02 9.1497981e-07 9.4177294e-01]]\n"
          ]
        }
      ],
      "source": [
        "filenames = [\n",
        "    'gs://practical-ml-vision-book/flowers_5_jpeg/flower_photos/dandelion/9818247_e2eac18894.jpg',\n",
        "    'gs://practical-ml-vision-book/flowers_5_jpeg/flower_photos/dandelion/9853885425_4a82356f1d_m.jpg',\n",
        "    'gs://practical-ml-vision-book/flowers_5_jpeg/flower_photos/daisy/9299302012_958c70564c_n.jpg',\n",
        "    'gs://practical-ml-vision-book/flowers_5_jpeg/flower_photos/tulips/8733586143_3139db6e9e_n.jpg',\n",
        "    'gs://practical-ml-vision-book/flowers_5_jpeg/flower_photos/tulips/8713397358_0505cc0176_n.jpg'\n",
        "]\n",
        "for filename in filenames:\n",
        "    img_bytes = read_from_jpegfile(filename)\n",
        "    img = preprocess(img_bytes)\n",
        "    img = tf.expand_dims(img, axis=0)\n",
        "    pred = model.predict(img)\n",
        "    print(pred)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ELU4z-RLttDW"
      },
      "source": [
        "## 클라이언트의 바이트를 처리할 시그니처 내보내기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N_SM1jU0ttDW",
        "outputId": "bd88956d-3efa-4514-9c94-b2af70019c38"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: export/flowers_model3/assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: export/flowers_model3/assets\n"
          ]
        }
      ],
      "source": [
        "@tf.function(input_signature=[tf.TensorSpec([None,], dtype=tf.string)])\n",
        "def predict_bytes(img_bytes):\n",
        "    input_images = tf.map_fn(\n",
        "        preprocess,\n",
        "        img_bytes,\n",
        "        fn_output_signature=tf.float32\n",
        "    )\n",
        "    batch_pred = model(input_images) # same as model.predict()\n",
        "    top_prob = tf.math.reduce_max(batch_pred, axis=[1])\n",
        "    pred_label_index = tf.math.argmax(batch_pred, axis=1)\n",
        "    pred_label = tf.gather(tf.convert_to_tensor(CLASS_NAMES), pred_label_index)\n",
        "    return {\n",
        "        'probability': top_prob,\n",
        "        'flower_type_int': pred_label_index,\n",
        "        'flower_type_str': pred_label\n",
        "    }\n",
        "\n",
        "@tf.function(input_signature=[tf.TensorSpec([None,], dtype=tf.string)])\n",
        "def predict_filename(filenames):\n",
        "    img_bytes = tf.map_fn(\n",
        "        tf.io.read_file,\n",
        "        filenames\n",
        "    )\n",
        "    result = predict_bytes(img_bytes)\n",
        "    result['filename'] = filenames\n",
        "    return result\n",
        "\n",
        "shutil.rmtree('export', ignore_errors=True)\n",
        "os.mkdir('export')\n",
        "model.save('export/flowers_model3',\n",
        "          signatures={\n",
        "              'serving_default': predict_filename,\n",
        "              'from_bytes': predict_bytes\n",
        "          })"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V5s3wdOgttDX",
        "outputId": "79430b47-27b2-402a-81c1-4c0e81771e27"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The given SavedModel MetaGraphDef contains SignatureDefs with the following keys:\n",
            "SignatureDef key: \"__saved_model_init_op\"\n",
            "SignatureDef key: \"from_bytes\"\n",
            "SignatureDef key: \"serving_default\"\n"
          ]
        }
      ],
      "source": [
        "!saved_model_cli show --tag_set serve --dir export/flowers_model3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WW1WSSq-ttDX",
        "outputId": "1d05e5de-a15b-43ff-d7a5-fd1db35977a4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The given SavedModel SignatureDef contains the following input(s):\n",
            "  inputs['filenames'] tensor_info:\n",
            "      dtype: DT_STRING\n",
            "      shape: (-1)\n",
            "      name: serving_default_filenames:0\n",
            "The given SavedModel SignatureDef contains the following output(s):\n",
            "  outputs['filename'] tensor_info:\n",
            "      dtype: DT_STRING\n",
            "      shape: (-1)\n",
            "      name: StatefulPartitionedCall_1:0\n",
            "  outputs['flower_type_int'] tensor_info:\n",
            "      dtype: DT_INT64\n",
            "      shape: (-1)\n",
            "      name: StatefulPartitionedCall_1:1\n",
            "  outputs['flower_type_str'] tensor_info:\n",
            "      dtype: DT_STRING\n",
            "      shape: (-1)\n",
            "      name: StatefulPartitionedCall_1:2\n",
            "  outputs['probability'] tensor_info:\n",
            "      dtype: DT_FLOAT\n",
            "      shape: (-1)\n",
            "      name: StatefulPartitionedCall_1:3\n",
            "Method name is: tensorflow/serving/predict\n"
          ]
        }
      ],
      "source": [
        "!saved_model_cli show --tag_set serve --dir export/flowers_model3 --signature_def serving_default"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HIy3m0TRttDX",
        "outputId": "94fae9dc-2c67-4287-b605-2029632254d8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The given SavedModel SignatureDef contains the following input(s):\n",
            "  inputs['img_bytes'] tensor_info:\n",
            "      dtype: DT_STRING\n",
            "      shape: (-1)\n",
            "      name: from_bytes_img_bytes:0\n",
            "The given SavedModel SignatureDef contains the following output(s):\n",
            "  outputs['flower_type_int'] tensor_info:\n",
            "      dtype: DT_INT64\n",
            "      shape: (-1)\n",
            "      name: StatefulPartitionedCall:0\n",
            "  outputs['flower_type_str'] tensor_info:\n",
            "      dtype: DT_STRING\n",
            "      shape: (-1)\n",
            "      name: StatefulPartitionedCall:1\n",
            "  outputs['probability'] tensor_info:\n",
            "      dtype: DT_FLOAT\n",
            "      shape: (-1)\n",
            "      name: StatefulPartitionedCall:2\n",
            "Method name is: tensorflow/serving/predict\n"
          ]
        }
      ],
      "source": [
        "!saved_model_cli show --tag_set serve --dir export/flowers_model3 --signature_def from_bytes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PjDjPH1cttDX"
      },
      "source": [
        "## 이미지 바이트 전송\n",
        "\n",
        "GCS에 중간 파일이 필요하지 않다. 우리는 단순히 파이썬의 파일 읽기 메서드를 사용한다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7EzbeiNRttDX",
        "outputId": "f8ab8b74-f9f8-4439-bb95-f7379c8e8342"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Copying gs://practical-ml-vision-book/flowers_5_jpeg/flower_photos/daisy/9299302012_958c70564c_n.jpg...\n",
            "/ [1 files][ 19.4 KiB/ 19.4 KiB]                                                \n",
            "Operation completed over 1 objects/19.4 KiB.                                     \n"
          ]
        }
      ],
      "source": [
        "!gsutil cp gs://practical-ml-vision-book/flowers_5_jpeg/flower_photos/daisy/9299302012_958c70564c_n.jpg /tmp/test.jpg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ap5Nh7wcttDY",
        "outputId": "13bb2767-1388-4dba-bc9e-22ff9a435103"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'probability': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.9947188], dtype=float32)>, 'flower_type_str': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'daisy'], dtype=object)>, 'flower_type_int': <tf.Tensor: shape=(1,), dtype=int64, numpy=array([0])>}\n"
          ]
        }
      ],
      "source": [
        "with open('/tmp/test.jpg', 'rb') as ifp:\n",
        "    img_bytes = ifp.read()\n",
        "    serving_fn = tf.keras.models.load_model('./export/flowers_model3').signatures['from_bytes']\n",
        "    pred = serving_fn(tf.convert_to_tensor([img_bytes]))\n",
        "    print(pred)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FNaB28eCttDY"
      },
      "source": [
        "## CAIP에 바이트 처리 모델 배포"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x85VC5b9ttDY",
        "outputId": "e3edaf42-f0fa-45d1-f8e6-0af8d272ef41"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Copying file://./export/flowers_model3/variables/variables.data-00000-of-00001 [Content-Type=application/octet-stream]...\n",
            "Copying file://./export/flowers_model3/variables/variables.index [Content-Type=application/octet-stream]...\n",
            "Copying file://./export/flowers_model3/saved_model.pb [Content-Type=application/octet-stream]...\n",
            "/ [3/3 files][ 10.7 MiB/ 10.7 MiB] 100% Done                                    \n",
            "Operation completed over 3 objects/10.7 MiB.                                     \n"
          ]
        }
      ],
      "source": [
        "%%bash\n",
        "BUCKET=\"ai-analytics-solutions-mlvisionbook\"  # CHANGE\n",
        "gsutil -m cp -r ./export/flowers_model3 gs://${BUCKET}/flowers_model3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sU2ElzjXttDY",
        "outputId": "2a0f1704-52ba-4a5f-fdcc-e5ef397bc8aa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Deploying model bytes\n",
            "Creating bytes endpoint now.\n",
            "The endpoint_id is 7318683646011899904\n",
            "Uploading bytes model now.\n",
            "The model_id is 2990680423643742208\n",
            "Deploying model now\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Using endpoint [https://us-central1-aiplatform.googleapis.com/]\n",
            "Using endpoint [https://us-central1-aiplatform.googleapis.com/]\n",
            "Waiting for operation [1561614649575604224]...\n",
            ".....done.\n",
            "Created Vertex AI endpoint: projects/563535018348/locations/us-central1/endpoints/7318683646011899904.\n",
            "Using endpoint [https://us-central1-aiplatform.googleapis.com/]\n",
            "Using endpoint [https://us-central1-aiplatform.googleapis.com/]\n",
            "Using endpoint [https://us-central1-aiplatform.googleapis.com/]\n",
            "Waiting for operation [8091834109262823424]...\n",
            ".....done.\n",
            "Using endpoint [https://us-central1-aiplatform.googleapis.com/]\n",
            "Using endpoint [https://us-central1-aiplatform.googleapis.com/]\n",
            "Waiting for operation [3867457658789298176]...\n",
            "........................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................done.\n",
            "Deployed a model to the endpoint 7318683646011899904. Id of the deployed model: 6992243041771716608.\n"
          ]
        }
      ],
      "source": [
        "%%bash\n",
        "BUCKET=\"ai-analytics-solutions-mlvisionbook\" # CHANGE\n",
        "./vertex_deploy.sh \\\n",
        "--endpoint_name=bytes \\\n",
        "--model_name=bytes \\\n",
        "--model_location=gs://${BUCKET}/flowers_model3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ylFKI0XtttDY"
      },
      "source": [
        "## 중요: 이 셀을 변경\n",
        "\n",
        "위의 엔드포인트 ID와 배포된 모델 ID를 기록해 둔다. 아래 셀에 입력한다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u5KRLW5xttDZ"
      },
      "outputs": [],
      "source": [
        "# 배포한 모델에 맞게 아래를 수정할 것\n",
        "import os\n",
        "os.environ['ENDPOINT_ID'] = '7318683646011899904' # 바\n",
        "os.environ['MODEL_ID'] = '6992243041771716608' # 꿔\n",
        "os.environ['PROJECT'] = 'ai-analytics-solutions' # 주\n",
        "os.environ['BUCKET'] = 'ai-analytics-solutions-mlvisionbook' # 세\n",
        "os.environ['REGION'] = 'us-central1' # 요"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iI0BCbefttDZ",
        "outputId": "8b5340f4-3dc5-48e5-9485-e38d328df470"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Copying gs://practical-ml-vision-book/flowers_5_jpeg/flower_photos/daisy/9299302012_958c70564c_n.jpg...\n",
            "/ [1 files][ 19.4 KiB/ 19.4 KiB]                                                \n",
            "Operation completed over 1 objects/19.4 KiB.                                     \n",
            "Copying gs://practical-ml-vision-book/flowers_5_jpeg/flower_photos/tulips/8713397358_0505cc0176_n.jpg...\n",
            "/ [1 files][ 34.6 KiB/ 34.6 KiB]                                                \n",
            "Operation completed over 1 objects/34.6 KiB.                                     \n"
          ]
        }
      ],
      "source": [
        "%%bash\n",
        "gsutil cp gs://practical-ml-vision-book/flowers_5_jpeg/flower_photos/daisy/9299302012_958c70564c_n.jpg /tmp/test1.jpg\n",
        "gsutil cp gs://practical-ml-vision-book/flowers_5_jpeg/flower_photos/tulips/8713397358_0505cc0176_n.jpg /tmp/test2.jpg"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Vm3EeHIttDZ"
      },
      "source": [
        "base-64로 인코딩된 데이터를 전달하는 방법에 유의하라."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F6MSMRATttDZ",
        "outputId": "fa5aae34-bb04-490c-af03-6b2dbfe4adf1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "b'{\\n  \"error\": {\\n    \"code\": 400,\\n    \"message\": \"Invalid JSON payload received. Unknown name \\\\\"signature_name\\\\\": Cannot find field.\",\\n    \"status\": \"INVALID_ARGUMENT\",\\n    \"details\": [\\n      {\\n        \"@type\": \"type.googleapis.com/google.rpc.BadRequest\",\\n        \"fieldViolations\": [\\n          {\\n            \"description\": \"Invalid JSON payload received. Unknown name \\\\\"signature_name\\\\\": Cannot find field.\"\\n          }\\n        ]\\n      }\\n    ]\\n  }\\n}\\n'\n"
          ]
        }
      ],
      "source": [
        "# 파이썬에서 호출\n",
        "import base64\n",
        "import json\n",
        "from oauth2client.client import GoogleCredentials\n",
        "import requests\n",
        "\n",
        "PROJECT = \"ai-analytics-solutions\"  # 변경\n",
        "REGION = \"us-central1\"  # 이 리전에 GPU/TPU 쿼타가 있는지 확인할 것\n",
        "ENDPOINT_ID = \"7318683646011899904\"\n",
        "\n",
        "def b64encode(filename):\n",
        "    with open(filename, 'rb') as ifp:\n",
        "        img_bytes = ifp.read()\n",
        "        return base64.b64encode(img_bytes)\n",
        "\n",
        "token = GoogleCredentials.get_application_default().get_access_token().access_token\n",
        "api = \"https://{}-aiplatform.googleapis.com/v1/projects/{}/locations/{}/endpoints/{}:predict\".format(\n",
        "    REGION, PROJECT, REGION, ENDPOINT_ID)\n",
        "headers = {\"Authorization\": \"Bearer \" + token }\n",
        "data = {\n",
        "    \"signature_name\": \"from_bytes\",  # currently bugged\n",
        "    \"instances\": [\n",
        "        {\n",
        "            \"img_bytes\": {\"b64\": b64encode('/tmp/test1.jpg')}\n",
        "        },\n",
        "        {\n",
        "            \"img_bytes\": {\"b64\": b64encode('/tmp/test2.jpg')}\n",
        "        },\n",
        "    ]\n",
        "}\n",
        "response = requests.post(api, json=data, headers=headers)\n",
        "print(response.content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Duu8mX3iXANE"
      },
      "source": [
        "## 라이선스\n",
        "Copyright 2020 Google Inc. Licensed under the Apache License, Version 2.0 (the \"License\"); you may not use this file except in compliance with the License. You may obtain a copy of the License at http://www.apache.org/licenses/LICENSE-2.0 Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "5UOm2etrwYCs"
      ],
      "name": "09d_bytes.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "environment": {
      "kernel": "python3",
      "name": "tf2-gpu.2-6.m87",
      "type": "gcloud",
      "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-6:m87"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
