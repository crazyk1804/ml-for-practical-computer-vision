{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 109
        },
        "id": "hiQ6zAoYhyaA",
        "outputId": "8dad2819-2812-45e0-ab53-7b81e445075a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "<table class=\"tfo-notebook-buttons\" align=\"left\"><td><a target=\"_blank\" href=\"https://console.cloud.google.com/ai-platform/notebooks/deploy-notebook?name=%EB%82%B4%EB%B3%B4%EB%82%B8+%EB%AA%A8%EB%8D%B8%EC%9D%98+%EC%8B%9C%EA%B7%B8%EB%8B%88%EC%B2%98+%EB%B0%94%EA%BE%B8%EA%B8%B0&download_url=https%3A%2F%2Fgithub.com%2Fychoi-kr%2Fpractical-ml-vision-book-ko%2Fraw%2Fmaster%2F09_deploying%2F09c_changesig.ipynb\"><img src=\"https://raw.githubusercontent.com/ychoi-kr/practical-ml-vision-book-ko/master/logo-cloud.png\"/>AI Platform Notebook에서 실행</a></td><td><a target=\"_blank\" href=\"https://colab.research.google.com/github/ychoi-kr/practical-ml-vision-book-ko/blob/master/09_deploying/09c_changesig.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Google Colab에서 실행</a></td><td><a target=\"_blank\" href=\"https://github.com/ychoi-kr/practical-ml-vision-book-ko/blob/master/09_deploying/09c_changesig.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />GitHub에서 소스 보기</a></td><td><a href=\"https://raw.githubusercontent.com/ychoi-kr/practical-ml-vision-book-ko/master/09_deploying/09c_changesig.ipynb\"><img src=\"https://www.tensorflow.org/images/download_logo_32px.png\" />노트북 내려받기</a></td></table><br/><br/><h1>내보낸 모델의 시그니처 바꾸기</h1>"
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "import urllib\n",
        "from IPython.display import Markdown as md\n",
        "\n",
        "### change to reflect your notebook\n",
        "_nb_loc = \"09_deploying/09c_changesig.ipynb\"\n",
        "_nb_title = \"내보낸 모델의 시그니처 바꾸기\"\n",
        "_nb_message = \"\"\n",
        "\n",
        "### no need to change any of this\n",
        "_icons=[\"https://raw.githubusercontent.com/ychoi-kr/practical-ml-vision-book-ko/master/logo-cloud.png\", \"https://www.tensorflow.org/images/colab_logo_32px.png\", \"https://www.tensorflow.org/images/GitHub-Mark-32px.png\", \"https://www.tensorflow.org/images/download_logo_32px.png\"]\n",
        "_links=[\"https://console.cloud.google.com/ai-platform/notebooks/deploy-notebook?\" + urllib.parse.urlencode({\"name\": _nb_title, \"download_url\": \"https://github.com/ychoi-kr/practical-ml-vision-book-ko/raw/master/\"+_nb_loc}), \"https://colab.research.google.com/github/ychoi-kr/practical-ml-vision-book-ko/blob/master/{0}\".format(_nb_loc), \"https://github.com/ychoi-kr/practical-ml-vision-book-ko/blob/master/{0}\".format(_nb_loc), \"https://raw.githubusercontent.com/ychoi-kr/practical-ml-vision-book-ko/master/{0}\".format(_nb_loc)]\n",
        "md(\"\"\"<table class=\"tfo-notebook-buttons\" align=\"left\"><td><a target=\"_blank\" href=\"{0}\"><img src=\"{4}\"/>AI Platform Notebook에서 실행</a></td><td><a target=\"_blank\" href=\"{1}\"><img src=\"{5}\" />Google Colab에서 실행</a></td><td><a target=\"_blank\" href=\"{2}\"><img src=\"{6}\" />GitHub에서 소스 보기</a></td><td><a href=\"{3}\"><img src=\"{7}\" />노트북 내려받기</a></td></table><br/><br/><h1>{8}</h1>{9}\"\"\".format(_links[0], _links[1], _links[2], _links[3], _icons[0], _icons[1], _icons[2], _icons[3], _nb_title, _nb_message))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a8HQYsAtC0Fv"
      },
      "source": [
        "# 내보낸 모델의 시그니처 바꾸기\n",
        "\n",
        "이 노트북에서는 앞서 훈련 및 저장한 모델(7장)을 가지고 시작한다.\n",
        "편의상 이 모델을 공개 버킷 [gs://practical-ml-vision-book/flowers_5_trained](gs://practical-ml-vision-book/flowers_5_trained)에 두었다.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5UOm2etrwYCs"
      },
      "source": [
        "## GPU 활성화 및 도우미 함수 셋업\n",
        "\n",
        "이 저장소의 노트북들은 GPU를 사용하면 더 빨리 실행된다.\n",
        "\n",
        "코랩에서:\n",
        "\n",
        "- 수정 → 노트 설정 메뉴로 이동\n",
        "- 하드웨어 가속기 드롭다운에서 GPU를 선택\n",
        "\n",
        "Cloud AI Platform Notebooks에서:\n",
        "\n",
        "- [https://console.cloud.google.com/ai-platform/notebooks](https://console.cloud.google.com/ai-platform/notebooks)로 이동\n",
        "- GPU를 포함한 인스턴스를 생성하거나, 인스턴스를 선택하고 GPU를 추가\n",
        "\n",
        "다음으로, 텐서플로로 GPU에 연결할 수 있는지 확인."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ugGJcxKAwhc2",
        "outputId": "8e946159-46cf-4aba-f53e-622e9ea8adee"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "TensorFlow version2.6.2\n",
            "Built with GPU support? Yes!\n",
            "There are 1 GPUs\n",
            "Found GPU at: /device:GPU:0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2021-12-05 02:36:35.367935: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-12-05 02:36:35.376968: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-12-05 02:36:35.377557: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-12-05 02:36:35.378801: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2021-12-05 02:36:35.379587: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-12-05 02:36:35.380207: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-12-05 02:36:35.380747: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-12-05 02:36:35.851798: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-12-05 02:36:35.852532: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-12-05 02:36:35.853109: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-12-05 02:36:35.853696: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /device:GPU:0 with 13839 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "print('TensorFlow version' + tf.version.VERSION)\n",
        "print('Built with GPU support? ' + ('Yes!' if tf.test.is_built_with_cuda() else 'Noooo!'))\n",
        "print('There are {} GPUs'.format(len(tf.config.experimental.list_physical_devices(\"GPU\"))))\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "    raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ykA05VC_rYRr"
      },
      "source": [
        "## 내보낸 모델\n",
        "\n",
        "7장에서 훈련 및 저장한 모델을 가지고 시작한다.\n",
        "\n",
        "<pre>\n",
        "  model.save(...)\n",
        "</pre>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RQ5vV1MrrYRr"
      },
      "outputs": [],
      "source": [
        "MODEL_LOCATION='gs://practical-ml-vision-book/flowers_5_trained'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fBoE2TUJrYRr",
        "outputId": "e7316aa3-ad79-4de3-b6d3-d9dff6e9b9c4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "gs://practical-ml-vision-book/flowers_5_trained/saved_model.pb\n",
            "gs://practical-ml-vision-book/flowers_5_trained/chkpts/\n",
            "gs://practical-ml-vision-book/flowers_5_trained/variables/\n"
          ]
        }
      ],
      "source": [
        "!gsutil ls {MODEL_LOCATION}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T2CRdhKCrYRs",
        "outputId": "a6b1c165-c1e9-4c4b-ae33-d2c5d8dfac04"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The given SavedModel SignatureDef contains the following input(s):\n",
            "  inputs['filenames'] tensor_info:\n",
            "      dtype: DT_STRING\n",
            "      shape: (-1)\n",
            "      name: serving_default_filenames:0\n",
            "The given SavedModel SignatureDef contains the following output(s):\n",
            "  outputs['flower_type_int'] tensor_info:\n",
            "      dtype: DT_INT64\n",
            "      shape: (-1)\n",
            "      name: StatefulPartitionedCall:0\n",
            "  outputs['flower_type_str'] tensor_info:\n",
            "      dtype: DT_STRING\n",
            "      shape: (-1)\n",
            "      name: StatefulPartitionedCall:1\n",
            "  outputs['probability'] tensor_info:\n",
            "      dtype: DT_FLOAT\n",
            "      shape: (-1)\n",
            "      name: StatefulPartitionedCall:2\n",
            "Method name is: tensorflow/serving/predict\n"
          ]
        }
      ],
      "source": [
        "!saved_model_cli show --tag_set serve --signature_def serving_default --dir {MODEL_LOCATION}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8TuR92OwrYRs"
      },
      "source": [
        "## Passing through an input\n",
        "\n",
        "시그니처에는 입력 파일 이름이 없다. 추가하자."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bVsj_CGzrYRs",
        "outputId": "5ac07c47-0da6-4c97-b48c-51a52963dafd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:SavedModel saved prior to TF 2.5 detected when loading Keras model. Please ensure that you are saving the model with model.save() or tf.keras.models.save_model(), *NOT* tf.saved_model.save(). To confirm, there should be a file named \"keras_metadata.pb\" in the SavedModel directory.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2021-12-05 02:36:42.073546: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-12-05 02:36:42.074258: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-12-05 02:36:42.074816: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-12-05 02:36:42.075456: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-12-05 02:36:42.076125: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-12-05 02:36:42.076667: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13839 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\n",
            "2021-12-05 02:37:00.706013: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n",
            "2021-12-05 02:37:00.717402: W tensorflow/python/util/util.cc:348] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: export/flowers_model/assets\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import shutil\n",
        "import tensorflow as tf\n",
        "model = tf.keras.models.load_model(MODEL_LOCATION)\n",
        "\n",
        "@tf.function(input_signature=[tf.TensorSpec([None,], dtype=tf.string)])\n",
        "def predict_flower_type(filenames):\n",
        "    old_fn = model.signatures['serving_default']\n",
        "    result = old_fn(filenames) # has flower_type_int etc.\n",
        "    result['filename'] = filenames\n",
        "    return result\n",
        "\n",
        "shutil.rmtree('export', ignore_errors=True)\n",
        "os.mkdir('export')\n",
        "model.save('export/flowers_model',\n",
        "          signatures={\n",
        "              'serving_default': predict_flower_type\n",
        "          })"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mXXHDLWlrYRt",
        "outputId": "45ed46ed-0cc4-4ef3-9851-b220fd0aea64"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The given SavedModel SignatureDef contains the following input(s):\n",
            "  inputs['filenames'] tensor_info:\n",
            "      dtype: DT_STRING\n",
            "      shape: (-1)\n",
            "      name: serving_default_filenames:0\n",
            "The given SavedModel SignatureDef contains the following output(s):\n",
            "  outputs['filename'] tensor_info:\n",
            "      dtype: DT_STRING\n",
            "      shape: (-1)\n",
            "      name: StatefulPartitionedCall:0\n",
            "  outputs['flower_type_int'] tensor_info:\n",
            "      dtype: DT_INT64\n",
            "      shape: (-1)\n",
            "      name: StatefulPartitionedCall:1\n",
            "  outputs['flower_type_str'] tensor_info:\n",
            "      dtype: DT_STRING\n",
            "      shape: (-1)\n",
            "      name: StatefulPartitionedCall:2\n",
            "  outputs['probability'] tensor_info:\n",
            "      dtype: DT_FLOAT\n",
            "      shape: (-1)\n",
            "      name: StatefulPartitionedCall:3\n",
            "Method name is: tensorflow/serving/predict\n"
          ]
        }
      ],
      "source": [
        "!saved_model_cli show --tag_set serve --signature_def serving_default --dir export/flowers_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dh0R4IX7rYRt",
        "outputId": "9ad88766-465f-45f9-b40d-bcd8aef1b5b6"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2021-12-05 02:37:09.518516: I tensorflow/stream_executor/cuda/cuda_dnn.cc:369] Loaded cuDNN version 8005\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'flower_type_str': <tf.Tensor: shape=(5,), dtype=string, numpy=\n",
            "array([b'dandelion', b'dandelion', b'daisy', b'tulips', b'tulips'],\n",
            "      dtype=object)>, 'filename': <tf.Tensor: shape=(5,), dtype=string, numpy=\n",
            "array([b'gs://practical-ml-vision-book/flowers_5_jpeg/flower_photos/dandelion/9818247_e2eac18894.jpg',\n",
            "       b'gs://practical-ml-vision-book/flowers_5_jpeg/flower_photos/dandelion/9853885425_4a82356f1d_m.jpg',\n",
            "       b'gs://practical-ml-vision-book/flowers_5_jpeg/flower_photos/daisy/9299302012_958c70564c_n.jpg',\n",
            "       b'gs://practical-ml-vision-book/flowers_5_jpeg/flower_photos/tulips/8733586143_3139db6e9e_n.jpg',\n",
            "       b'gs://practical-ml-vision-book/flowers_5_jpeg/flower_photos/tulips/8713397358_0505cc0176_n.jpg'],\n",
            "      dtype=object)>, 'probability': <tf.Tensor: shape=(5,), dtype=float32, numpy=\n",
            "array([0.6191508 , 0.99998426, 0.99508286, 0.97518593, 0.9549181 ],\n",
            "      dtype=float32)>, 'flower_type_int': <tf.Tensor: shape=(5,), dtype=int64, numpy=array([1, 1, 0, 4, 4])>}\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "serving_fn = tf.keras.models.load_model('export/flowers_model').signatures['serving_default']\n",
        "filenames = [\n",
        "    'gs://practical-ml-vision-book/flowers_5_jpeg/flower_photos/dandelion/9818247_e2eac18894.jpg',\n",
        "    'gs://practical-ml-vision-book/flowers_5_jpeg/flower_photos/dandelion/9853885425_4a82356f1d_m.jpg',\n",
        "    'gs://practical-ml-vision-book/flowers_5_jpeg/flower_photos/daisy/9299302012_958c70564c_n.jpg',\n",
        "    'gs://practical-ml-vision-book/flowers_5_jpeg/flower_photos/tulips/8733586143_3139db6e9e_n.jpg',\n",
        "    'gs://practical-ml-vision-book/flowers_5_jpeg/flower_photos/tulips/8713397358_0505cc0176_n.jpg'\n",
        "]\n",
        "pred = serving_fn(tf.convert_to_tensor(filenames))\n",
        "print(pred)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O77FKeYYrYRt"
      },
      "source": [
        "## 다중 시그니처\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EijzgXRerYRu",
        "outputId": "5ca8a092-4c64-4d23-a862-72c8c5d7bd95"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:SavedModel saved prior to TF 2.5 detected when loading Keras model. Please ensure that you are saving the model with model.save() or tf.keras.models.save_model(), *NOT* tf.saved_model.save(). To confirm, there should be a file named \"keras_metadata.pb\" in the SavedModel directory.\n",
            "INFO:tensorflow:Assets written to: export/flowers_model2/assets\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import shutil\n",
        "import tensorflow as tf\n",
        "model = tf.keras.models.load_model(MODEL_LOCATION)\n",
        "old_fn = model.signatures['serving_default']\n",
        "\n",
        "@tf.function(input_signature=[tf.TensorSpec([None,], dtype=tf.string)])\n",
        "def pass_through_input(filenames):\n",
        "    result = old_fn(filenames) # has flower_type_int etc.\n",
        "    result['filename'] = filenames\n",
        "    return result\n",
        "\n",
        "shutil.rmtree('export', ignore_errors=True)\n",
        "os.mkdir('export')\n",
        "model.save('export/flowers_model2',\n",
        "          signatures={\n",
        "              'serving_default': old_fn,\n",
        "              'input_pass_through': pass_through_input\n",
        "          })"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PlRNEcZZrYRu",
        "outputId": "b142833c-3e38-4b44-c083-62e76f025a86"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The given SavedModel MetaGraphDef contains SignatureDefs with the following keys:\n",
            "SignatureDef key: \"__saved_model_init_op\"\n",
            "SignatureDef key: \"input_pass_through\"\n",
            "SignatureDef key: \"serving_default\"\n"
          ]
        }
      ],
      "source": [
        "!saved_model_cli show --tag_set serve --dir export/flowers_model2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5NlHkTaOrYRu",
        "outputId": "98be6262-1c8a-405c-dd2a-a3c6758d6979"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The given SavedModel SignatureDef contains the following input(s):\n",
            "  inputs['filenames'] tensor_info:\n",
            "      dtype: DT_STRING\n",
            "      shape: (-1)\n",
            "      name: serving_default_filenames:0\n",
            "The given SavedModel SignatureDef contains the following output(s):\n",
            "  outputs['flower_type_int'] tensor_info:\n",
            "      dtype: DT_INT64\n",
            "      shape: (-1)\n",
            "      name: StatefulPartitionedCall_1:0\n",
            "  outputs['flower_type_str'] tensor_info:\n",
            "      dtype: DT_STRING\n",
            "      shape: (-1)\n",
            "      name: StatefulPartitionedCall_1:1\n",
            "  outputs['probability'] tensor_info:\n",
            "      dtype: DT_FLOAT\n",
            "      shape: (-1)\n",
            "      name: StatefulPartitionedCall_1:2\n",
            "Method name is: tensorflow/serving/predict\n"
          ]
        }
      ],
      "source": [
        "!saved_model_cli show --tag_set serve --dir export/flowers_model2 --signature_def serving_default"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yMZLeHavrYRu",
        "outputId": "25da61ba-4020-462b-bd5b-50edd690dcb6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The given SavedModel SignatureDef contains the following input(s):\n",
            "  inputs['filenames'] tensor_info:\n",
            "      dtype: DT_STRING\n",
            "      shape: (-1)\n",
            "      name: input_pass_through_filenames:0\n",
            "The given SavedModel SignatureDef contains the following output(s):\n",
            "  outputs['filename'] tensor_info:\n",
            "      dtype: DT_STRING\n",
            "      shape: (-1)\n",
            "      name: StatefulPartitionedCall:0\n",
            "  outputs['flower_type_int'] tensor_info:\n",
            "      dtype: DT_INT64\n",
            "      shape: (-1)\n",
            "      name: StatefulPartitionedCall:1\n",
            "  outputs['flower_type_str'] tensor_info:\n",
            "      dtype: DT_STRING\n",
            "      shape: (-1)\n",
            "      name: StatefulPartitionedCall:2\n",
            "  outputs['probability'] tensor_info:\n",
            "      dtype: DT_FLOAT\n",
            "      shape: (-1)\n",
            "      name: StatefulPartitionedCall:3\n",
            "Method name is: tensorflow/serving/predict\n"
          ]
        }
      ],
      "source": [
        "!saved_model_cli show --tag_set serve --dir export/flowers_model2 --signature_def input_pass_through"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LFpliDzmrYRu"
      },
      "source": [
        "## 다중 시그니처 모델을 REST API로 배포"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oKiFYLqZrYRv",
        "outputId": "adb6f55c-a3da-4623-b247-7377e5345dff"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Copying file://./export/flowers_model2/keras_metadata.pb [Content-Type=application/octet-stream]...\n",
            "Copying file://./export/flowers_model2/variables/variables.index [Content-Type=application/octet-stream]...\n",
            "Copying file://./export/flowers_model2/variables/variables.data-00000-of-00001 [Content-Type=application/octet-stream]...\n",
            "Copying file://./export/flowers_model2/saved_model.pb [Content-Type=application/octet-stream]...\n",
            "/ [4/4 files][ 10.9 MiB/ 10.9 MiB] 100% Done                                    \n",
            "Operation completed over 4 objects/10.9 MiB.                                     \n"
          ]
        }
      ],
      "source": [
        "%%bash\n",
        "BUCKET=\"ai-analytics-solutions-mlvisionbook\" # CHANGE\n",
        "gsutil -m cp -r ./export/flowers_model2 gs://${BUCKET}/flowers_model2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r2UGHX3irYRv",
        "outputId": "cdaa8356-542f-47e8-cff4-bda597f9bf9b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Deploying model multi\n",
            "Creating multi endpoint now.\n",
            "The endpoint_id is 130472447798411264\n",
            "Uploading multi model now.\n",
            "The model_id is 8769849878676242432\n",
            "Deploying model now\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Using endpoint [https://us-central1-aiplatform.googleapis.com/]\n",
            "Using endpoint [https://us-central1-aiplatform.googleapis.com/]\n",
            "Waiting for operation [1944520467301793792]...\n",
            "......done.\n",
            "Created Vertex AI endpoint: projects/379218021631/locations/us-central1/endpoints/130472447798411264.\n",
            "Using endpoint [https://us-central1-aiplatform.googleapis.com/]\n",
            "Using endpoint [https://us-central1-aiplatform.googleapis.com/]\n",
            "Using endpoint [https://us-central1-aiplatform.googleapis.com/]\n",
            "Waiting for operation [6376062500634361856]...\n",
            "......................done.\n",
            "Using endpoint [https://us-central1-aiplatform.googleapis.com/]\n",
            "Using endpoint [https://us-central1-aiplatform.googleapis.com/]\n",
            "Waiting for operation [2946571384391729152]...\n",
            "..............................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................done.\n",
            "Deployed a model to the endpoint 130472447798411264. Id of the deployed model: 1810350293179695104.\n"
          ]
        }
      ],
      "source": [
        "%%bash\n",
        "BUCKET=\"ai-analytics-solutions-mlvisionbook\" # CHANGE\n",
        "./vertex_deploy.sh \\\n",
        "--endpoint_name=multi \\\n",
        "--model_name=multi \\\n",
        "--model_location=gs://${BUCKET}/flowers_model2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "88PvoM6UrYRv"
      },
      "source": [
        "## 중요: 이 셀을 변경\n",
        "\n",
        "위의 엔드포인트 ID와 배포된 모델 ID를 기록해 둔다. 아래 셀에 입력한다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "75Tp5clorYRv"
      },
      "outputs": [],
      "source": [
        "# 배포한 모델에 맞게 아래를 수정할 것\n",
        "import os\n",
        "os.environ['ENDPOINT_ID'] = '130472447798411264' # 바\n",
        "os.environ['MODEL_ID'] = '1810350293179695104' # 꿔\n",
        "os.environ['PROJECT'] = 'ai-analytics-solutions' # 주\n",
        "os.environ['BUCKET'] = 'ai-analytics-solutions-mlvisionbook' # 세\n",
        "os.environ['REGION'] = 'us-central1' # 요"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "co8L1i08rYRv",
        "outputId": "792deac1-806b-41c4-9c4d-d670c21a9dd0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting request.json\n"
          ]
        }
      ],
      "source": [
        "%%writefile request.json\n",
        "{\n",
        "    \"instances\": [\n",
        "        {\n",
        "            \"filenames\": \"gs://practical-ml-vision-book/flowers_5_jpeg/flower_photos/dandelion/9818247_e2eac18894.jpg\"\n",
        "        },\n",
        "        {\n",
        "            \"filenames\": \"gs://practical-ml-vision-book/flowers_5_jpeg/flower_photos/dandelion/9853885425_4a82356f1d_m.jpg\"\n",
        "        },\n",
        "        {\n",
        "            \"filenames\": \"gs://practical-ml-vision-book/flowers_5_jpeg/flower_photos/daisy/9299302012_958c70564c_n.jpg\"\n",
        "        },\n",
        "        {\n",
        "            \"filenames\": \"gs://practical-ml-vision-book/flowers_5_jpeg/flower_photos/tulips/8733586143_3139db6e9e_n.jpg\"\n",
        "        },\n",
        "        {\n",
        "            \"filenames\": \"gs://practical-ml-vision-book/flowers_5_jpeg/flower_photos/tulips/8713397358_0505cc0176_n.jpg\"\n",
        "        }\n",
        "    ]\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OblHlj7YrYRw",
        "outputId": "71763bc6-cf77-4d21-e3ee-d4732c70f58f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{\n",
            "  \"deployedModelId\": \"1810350293179695104\",\n",
            "  \"model\": \"projects/379218021631/locations/us-central1/models/8769849878676242432\",\n",
            "  \"modelDisplayName\": \"multi\",\n",
            "  \"predictions\": [\n",
            "    {\n",
            "      \"flower_type_int\": 1,\n",
            "      \"flower_type_str\": \"dandelion\",\n",
            "      \"probability\": 0.619152546\n",
            "    },\n",
            "    {\n",
            "      \"flower_type_int\": 1,\n",
            "      \"flower_type_str\": \"dandelion\",\n",
            "      \"probability\": 0.999984384\n",
            "    },\n",
            "    {\n",
            "      \"flower_type_int\": 0,\n",
            "      \"flower_type_str\": \"daisy\",\n",
            "      \"probability\": 0.995082855\n",
            "    },\n",
            "    {\n",
            "      \"flower_type_int\": 4,\n",
            "      \"flower_type_str\": \"tulips\",\n",
            "      \"probability\": 0.975185812\n",
            "    },\n",
            "    {\n",
            "      \"flower_type_int\": 4,\n",
            "      \"flower_type_str\": \"tulips\",\n",
            "      \"probability\": 0.954917\n",
            "    }\n",
            "  ]\n",
            "}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Using endpoint [https://us-central1-prediction-aiplatform.googleapis.com/]\n"
          ]
        }
      ],
      "source": [
        "%%bash\n",
        "gcloud ai endpoints predict ${ENDPOINT_ID} \\\n",
        "--region=${REGION} \\\n",
        "--json-request=request.json \\\n",
        "--format=json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yJ9UlQSwrYRw",
        "outputId": "435908e7-335e-41b9-c225-196609da4f34"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting request.json\n"
          ]
        }
      ],
      "source": [
        "%%writefile request.json\n",
        "{\n",
        "    \"signature_name\": \"input_pass_through\",\n",
        "    \"instances\": [\n",
        "        {\n",
        "            \"filenames\": \"gs://practical-ml-vision-book/flowers_5_jpeg/flower_photos/dandelion/9818247_e2eac18894.jpg\"\n",
        "        },\n",
        "        {\n",
        "            \"filenames\": \"gs://practical-ml-vision-book/flowers_5_jpeg/flower_photos/dandelion/9853885425_4a82356f1d_m.jpg\"\n",
        "        },\n",
        "        {\n",
        "            \"filenames\": \"gs://practical-ml-vision-book/flowers_5_jpeg/flower_photos/daisy/9299302012_958c70564c_n.jpg\"\n",
        "        },\n",
        "        {\n",
        "            \"filenames\": \"gs://practical-ml-vision-book/flowers_5_jpeg/flower_photos/tulips/8733586143_3139db6e9e_n.jpg\"\n",
        "        },\n",
        "        {\n",
        "            \"filenames\": \"gs://practical-ml-vision-book/flowers_5_jpeg/flower_photos/tulips/8713397358_0505cc0176_n.jpg\"\n",
        "        }\n",
        "    ]\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M4otx6hwrYRw",
        "outputId": "e03a1d8d-da9b-4e53-d381-8fd18024fc3d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{\n",
            "  \"deployedModelId\": \"1810350293179695104\",\n",
            "  \"model\": \"projects/379218021631/locations/us-central1/models/8769849878676242432\",\n",
            "  \"modelDisplayName\": \"multi\",\n",
            "  \"predictions\": [\n",
            "    {\n",
            "      \"flower_type_int\": 1,\n",
            "      \"flower_type_str\": \"dandelion\",\n",
            "      \"probability\": 0.619152546\n",
            "    },\n",
            "    {\n",
            "      \"flower_type_int\": 1,\n",
            "      \"flower_type_str\": \"dandelion\",\n",
            "      \"probability\": 0.999984384\n",
            "    },\n",
            "    {\n",
            "      \"flower_type_int\": 0,\n",
            "      \"flower_type_str\": \"daisy\",\n",
            "      \"probability\": 0.995082855\n",
            "    },\n",
            "    {\n",
            "      \"flower_type_int\": 4,\n",
            "      \"flower_type_str\": \"tulips\",\n",
            "      \"probability\": 0.975185812\n",
            "    },\n",
            "    {\n",
            "      \"flower_type_int\": 4,\n",
            "      \"flower_type_str\": \"tulips\",\n",
            "      \"probability\": 0.954917\n",
            "    }\n",
            "  ]\n",
            "}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Using endpoint [https://us-central1-prediction-aiplatform.googleapis.com/]\n"
          ]
        }
      ],
      "source": [
        "%%bash\n",
        "gcloud ai endpoints predict ${ENDPOINT_ID} \\\n",
        "--region=${REGION} \\\n",
        "--json-request=request.json \\\n",
        "--format=json"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vLbZV14zrYRw"
      },
      "source": [
        "이것은 버그다. 리포트했다. 빨리 고쳐지면 좋겠다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CIHBKD9trYRw",
        "outputId": "9b155bd8-b365-41d7-b4ca-27077b84149d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "b'{\\n  \"error\": {\\n    \"code\": 400,\\n    \"message\": \"Invalid JSON payload received. Unknown name \\\\\"signature_name\\\\\": Cannot find field.\",\\n    \"status\": \"INVALID_ARGUMENT\",\\n    \"details\": [\\n      {\\n        \"@type\": \"type.googleapis.com/google.rpc.BadRequest\",\\n        \"fieldViolations\": [\\n          {\\n            \"description\": \"Invalid JSON payload received. Unknown name \\\\\"signature_name\\\\\": Cannot find field.\"\\n          }\\n        ]\\n      }\\n    ]\\n  }\\n}\\n'\n"
          ]
        }
      ],
      "source": [
        "# 파이썬에서 호출\n",
        "import json\n",
        "from oauth2client.client import GoogleCredentials\n",
        "import requests\n",
        "\n",
        "PROJECT = os.environ['PROJECT']\n",
        "REGION = os.environ['REGION']\n",
        "ENDPOINT_ID = os.environ['ENDPOINT_ID']\n",
        "\n",
        "token = GoogleCredentials.get_application_default().get_access_token().access_token\n",
        "api = \"https://{}-aiplatform.googleapis.com/v1/projects/{}/locations/{}/endpoints/{}:predict\".format(\n",
        "    REGION, PROJECT, REGION, ENDPOINT_ID)\n",
        "headers = {\"Authorization\": \"Bearer \" + token }\n",
        "data = {\n",
        "    \"signature_name\": \"input_pass_through\",  # currently bugged\n",
        "    \"instances\": [\n",
        "        {\n",
        "            \"filenames\": \"gs://practical-ml-vision-book/flowers_5_jpeg/flower_photos/dandelion/9818247_e2eac18894.jpg\"\n",
        "        },\n",
        "        {\n",
        "            \"filenames\": \"gs://practical-ml-vision-book/flowers_5_jpeg/flower_photos/dandelion/9853885425_4a82356f1d_m.jpg\"\n",
        "        },\n",
        "        {\n",
        "            \"filenames\": \"gs://practical-ml-vision-book/flowers_5_jpeg/flower_photos/daisy/9299302012_958c70564c_n.jpg\"\n",
        "        },\n",
        "        {\n",
        "            \"filenames\": \"gs://practical-ml-vision-book/flowers_5_jpeg/flower_photos/tulips/8733586143_3139db6e9e_n.jpg\"\n",
        "        },\n",
        "        {\n",
        "            \"filenames\": \"gs://practical-ml-vision-book/flowers_5_jpeg/flower_photos/tulips/8713397358_0505cc0176_n.jpg\"\n",
        "        }\n",
        "    ]\n",
        "}\n",
        "response = requests.post(api, json=data, headers=headers)\n",
        "print(response.content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Duu8mX3iXANE"
      },
      "source": [
        "## 라이선스\n",
        "Copyright 2020 Google Inc. Licensed under the Apache License, Version 2.0 (the \"License\"); you may not use this file except in compliance with the License. You may obtain a copy of the License at http://www.apache.org/licenses/LICENSE-2.0 Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "5UOm2etrwYCs"
      ],
      "name": "09c_changesig.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "environment": {
      "kernel": "python3",
      "name": "tf2-gpu.2-6.m87",
      "type": "gcloud",
      "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-6:m87"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
